{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f45c6fdb",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3b0d49",
   "metadata": {},
   "source": [
    "## Apply K means algorithm to find clusters of different types of customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fdaddb-a0dc-40e2-b1f6-05d0f80a0802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col].astype(str))\n",
    "\n",
    "# Select numeric columns for scaling\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaled_data = StandardScaler().fit_transform(df[numeric_cols])\n",
    "\n",
    "# Elbow method\n",
    "inertia = []\n",
    "K = range(1, 10)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(scaled_data)  # Use scaled_data here\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow Method\n",
    "plt.plot(K, inertia, 'bx-')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia (Sum of Squared Distances)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cffd28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_avg = []\n",
    "K = range(2, 10)  # Silhouette score requires at least two clusters\n",
    "\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = kmeans.fit_predict(scaled_data)\n",
    "    silhouette_avg.append(silhouette_score(scaled_data, labels))\n",
    "\n",
    "# Plot Silhouette Score\n",
    "plt.plot(K, silhouette_avg, 'bx-')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d8975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA first\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Apply KMeans clustering on the PCA-transformed data\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Recalculate centroids in the PCA space\n",
    "centroids_pca = kmeans.cluster_centers_\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot data points with cluster labels\n",
    "scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, s=60, cmap='viridis')\n",
    "ax.set_title('Learned Cluster Labels with Centroids', fontsize=14)\n",
    "ax.set_xlabel('PCA Feature 1', fontsize=12)\n",
    "ax.set_ylabel('PCA Feature 2', fontsize=12)\n",
    "fig.colorbar(scatter, ax=ax, label='Cluster Label')\n",
    "\n",
    "# Plot centroids\n",
    "ax.scatter(centroids_pca[:, 0], centroids_pca[:, 1], c='black', s=200, alpha=0.6, marker='X', label='Centroids')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc5ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the original data and cluster labels\n",
    "original_clustered_df = df.copy()\n",
    "original_clustered_df['Cluster'] = labels\n",
    "\n",
    "# Print 10 samples for each cluster\n",
    "for cluster in range(3):  # assuming 3 clusters\n",
    "    print(f\"\\n--- Cluster {cluster} Samples ---\")\n",
    "    print(original_clustered_df[original_clustered_df['Cluster'] == cluster].sample(n=10, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e44a651",
   "metadata": {},
   "source": [
    "# Detailed Cluster Analysis\n",
    "## 1. Demographic Composition\n",
    "Cluster 1:\n",
    "\n",
    "Age Balance: 50/50 split between 18-30 and 31-50 age groups\n",
    "Gender Diversity: Predominantly Female, with some Male and \"Prefer not to say\"\n",
    "Most diverse demographic profile\n",
    "\n",
    "Cluster 2:\n",
    "\n",
    "Age Skew: Heavily weighted towards 18-30 (80% of sample)\n",
    "Gender: More varied gender representation\n",
    "Younger, more diverse demographic\n",
    "\n",
    "Cluster 3:\n",
    "\n",
    "Age Concentration: Strongly 31-50 age group (90% of sample)\n",
    "Gender: More Male-dominated\n",
    "Mature, stable demographic\n",
    "\n",
    "## 2. Purchase Behavior\n",
    "Cluster 1:\n",
    "\n",
    "Purchase Frequency: Most variable\n",
    "Categories: Widest range (Beauty, Clothing, Groceries, Others)\n",
    "Least predictable purchasing pattern\n",
    "\n",
    "Cluster 2:\n",
    "\n",
    "Purchase Frequency: Consistent \"Few times a week\"\n",
    "Strong focus on Beauty and Personal Care\n",
    "More intentional, planned purchasing\n",
    "\n",
    "Cluster 3:\n",
    "\n",
    "Purchase Frequency: Most conservative (Once a month to Few times a month)\n",
    "Practical categories: Groceries, Home & Kitchen\n",
    "Most budget-conscious cluster\n",
    "\n",
    "## 3. Digital Interaction Patterns\n",
    "Cluster 1:\n",
    "\n",
    "Browsing: Mostly \"Few times a month\"\n",
    "Search Methods: Most eclectic (categories, keywords mixed)\n",
    "Exploration: Balanced between first page and multiple pages\n",
    "\n",
    "Cluster 2:\n",
    "\n",
    "Browsing: More frequent (Few times a week)\n",
    "Search Methods: Most sophisticated (heavy filter use)\n",
    "Exploration: Consistently multi-page browsers\n",
    "Most digitally engaged cluster\n",
    "\n",
    "Cluster 3:\n",
    "\n",
    "Browsing: Moderate frequency\n",
    "Search Methods: Most pragmatic\n",
    "Exploration: Mix of first page and multiple pages\n",
    "Most utilitarian digital interaction\n",
    "\n",
    "## 4. Recommendation and Personalization\n",
    "Cluster 1:\n",
    "\n",
    "Personalized Recommendation Purchase: Mostly \"Sometimes\"\n",
    "Moderate openness to personalization\n",
    "Inconsistent recommendation response\n",
    "\n",
    "Cluster 2:\n",
    "\n",
    "Personalized Recommendation Purchase: More \"Yes\" responses\n",
    "Highest recommendation frequency\n",
    "Most receptive to personalized marketing\n",
    "\n",
    "Cluster 3:\n",
    "\n",
    "Personalized Recommendation Purchase: Mixed, leaning conservative\n",
    "Least responsive to personalization\n",
    "Most skeptical about recommendations\n",
    "\n",
    "## 5. Review and Satisfaction Dynamics\n",
    "Cluster 1:\n",
    "\n",
    "Review Reliability: Most varied (Rarely to Heavily)\n",
    "Review Helpfulness: Inconsistent\n",
    "Shopping Satisfaction: Low (mostly 1-2)\n",
    "\n",
    "Cluster 2:\n",
    "\n",
    "Review Reliability: Consistently Moderate\n",
    "Review Helpfulness: More positive\n",
    "Shopping Satisfaction: Moderate (3-4)\n",
    "Most balanced review interaction\n",
    "\n",
    "Cluster 3:\n",
    "\n",
    "Review Reliability: Lower (Rarely to Occasionally)\n",
    "Review Helpfulness: Most conservative\n",
    "Shopping Satisfaction: Lowest (1-2)\n",
    "Most critical customer segment\n",
    "\n",
    "## 6. Improvement and Service Appreciation\n",
    "Cluster 1:\n",
    "\n",
    "Service Appreciation: Consistently high (7-8)\n",
    "Improvement Areas: Widely varied\n",
    "More forgiving, constructive feedback\n",
    "\n",
    "Cluster 2:\n",
    "\n",
    "Service Appreciation: Lowest and most variable\n",
    "Improvement Areas: Focused on specific aspects\n",
    "Most vocal about potential improvements\n",
    "\n",
    "Cluster 3:\n",
    "\n",
    "Service Appreciation: Mixed\n",
    "Improvement Areas: Practical, specific concerns\n",
    "Most direct in feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0fb7d",
   "metadata": {},
   "source": [
    " ## Cluster 1: The Casual, Mixed-Interest Shoppers \n",
    "Key Characteristics:\n",
    "\n",
    "Age Range: Predominantly 18-30 and 31-50\n",
    "Purchase Frequency: Varied (few times a month to multiple times a week)\n",
    "Browsing Behavior:\n",
    "\n",
    "Mostly browse few times a month\n",
    "Mix of search methods (categories, keywords)\n",
    "Tend to explore multiple pages or first page of search results\n",
    "\n",
    "\n",
    "Shopping Preferences:\n",
    "\n",
    "Diverse purchase categories (Beauty, Clothing, Groceries)\n",
    "Moderate use of personalized recommendations\n",
    "Mixed attitude towards add-to-cart behavior\n",
    "\n",
    "\n",
    "Review Interaction:\n",
    "\n",
    "Varied review reliability (from rarely to heavily)\n",
    "Mixed review helpfulness\n",
    "\n",
    "\n",
    "Satisfaction Levels:\n",
    "\n",
    "Moderate shopping satisfaction (mostly 1-2 on a scale)\n",
    "Moderate service appreciation\n",
    "\n",
    "\n",
    "\n",
    "## Cluster 2: The Exploratory Shoppers\n",
    "Key Characteristics:\n",
    "\n",
    "Age Range: Primarily 18-30, some 31-50\n",
    "Purchase Frequency: Moderate (few times a week to few times a month)\n",
    "Browsing Behavior:\n",
    "\n",
    "Consistent few times a week browsing\n",
    "Diverse search methods (categories, filters, keywords)\n",
    "Tend to explore multiple pages\n",
    "\n",
    "\n",
    "Shopping Preferences:\n",
    "\n",
    "Strong focus on Beauty and Personal Care\n",
    "More likely to use personalized recommendations\n",
    "More likely to add items to cart\n",
    "\n",
    "\n",
    "Review Interaction:\n",
    "\n",
    "Moderate to high review reliability\n",
    "More positive about review helpfulness\n",
    "\n",
    "\n",
    "Satisfaction Levels:\n",
    "\n",
    "Slightly higher shopping satisfaction (3-4 range)\n",
    "Lower service appreciation\n",
    "\n",
    "\n",
    "Unique Trait: More open to personalized recommendations and exploring product options\n",
    "\n",
    "## Cluster 3: The Occasional Shoppers\n",
    "Key Characteristics:\n",
    "\n",
    "Age Range: Predominantly 31-50\n",
    "Purchase Frequency: Moderate (once a month to few times a month)\n",
    "Browsing Behavior:\n",
    "\n",
    "Consistent few times a week to few times a month browsing\n",
    "Mix of search methods\n",
    "Often explore multiple pages\n",
    "\n",
    "\n",
    "Shopping Preferences:\n",
    "\n",
    "Focused on Groceries, Beauty, and Home/Kitchen\n",
    "Moderate use of personalized recommendations\n",
    "More cautious about adding to cart\n",
    "\n",
    "\n",
    "Review Interaction:\n",
    "\n",
    "Lower review reliability (rarely to occasionally)\n",
    "More conservative about review helpfulness\n",
    "\n",
    "\n",
    "Satisfaction Levels:\n",
    "\n",
    "Lower shopping satisfaction (mostly 1-2 range)\n",
    "Mixed service appreciation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea1abeb",
   "metadata": {},
   "source": [
    "### Random Forest to determine which feature has the greatest importance on Purchase Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca08ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the new target variable\n",
    "target_variable = 'Cart_Abandonment_Factors'\n",
    "\n",
    "# Drop rows with missing target values\n",
    "df = df.dropna(subset=[target_variable])\n",
    "\n",
    "# Define feature columns\n",
    "features = [\n",
    "    'Gender', 'Browsing_Frequency', 'Product_Search_Method',\n",
    "    'Search_Result_Exploration', 'Customer_Reviews_Importance',\n",
    "    'Add_to_Cart_Browsing', 'Cart_Completion_Frequency', \n",
    "    'Saveforlater_Frequency', 'Review_Left', 'Review_Reliability',\n",
    "    'Review_Helpfulness', 'Shopping_Satisfaction'\n",
    "]\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "for col in features:\n",
    "    if df[col].dtype == 'object' or isinstance(df[col].iloc[0], str):  # Check for string dtype\n",
    "        df[col] = label_encoder.fit_transform(df[col].astype(str))\n",
    "\n",
    "# Ensure target is encoded\n",
    "if df[target_variable].dtype == 'object' or isinstance(df[target_variable].iloc[0], str):\n",
    "    df[target_variable] = label_encoder.fit_transform(df[target_variable].astype(str))\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df[features]\n",
    "y = df[target_variable]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Feature importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances)\n",
    "plt.title('Feature Importance on Cart Abandonment Factors')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "# Display feature importance\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c7507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Map Purchase Frequency to numeric values\n",
    "purchase_frequency_mapping = {\n",
    "    \"Few times a month\": 2,\n",
    "    \"Once a month\": 1,\n",
    "    \"Less than once a month\": 0\n",
    "}\n",
    "df['Purchase_Frequency_Numeric'] = df['Purchase_Frequency'].map(purchase_frequency_mapping)\n",
    "\n",
    "# Drop rows with missing target values\n",
    "df = df.dropna(subset=['Purchase_Frequency_Numeric'])\n",
    "\n",
    "# Define feature columns\n",
    "features = [\n",
    "    'Gender', 'age', 'Browsing_Frequency', 'Product_Search_Method',\n",
    "    'Search_Result_Exploration', 'Customer_Reviews_Importance',\n",
    "    'Add_to_Cart_Browsing', 'Cart_Completion_Frequency', \n",
    "    'Saveforlater_Frequency', 'Review_Left', 'Review_Reliability',\n",
    "    'Review_Helpfulness', 'Shopping_Satisfaction'\n",
    "]\n",
    "\n",
    "# Ensure categorical features are encoded\n",
    "label_encoder = LabelEncoder()\n",
    "for col in features:\n",
    "    if df[col].dtype == 'object' or isinstance(df[col].iloc[0], str):  # Check for string dtype\n",
    "        df[col] = label_encoder.fit_transform(df[col].astype(str))\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df[features]\n",
    "y = df['Purchase_Frequency_Numeric']\n",
    "\n",
    "# Ensure target variable is numeric\n",
    "y = y.astype(int)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test, y_pred, target_names=[\n",
    "    \"Less than once a month\", \"Once a month\", \"Few times a month\"\n",
    "])\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[\n",
    "    \"Less than once a month\", \"Once a month\", \"Few times a month\"\n",
    "])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Feature importance from the best model\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': best_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances)\n",
    "plt.title('Feature Importance on Purchase Frequency (After Tuning)')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "# Display feature importance\n",
    "print(feature_importances)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
